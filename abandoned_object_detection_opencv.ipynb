{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a0c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce20bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(r\"C:\\Users\\MTC1COB\\Downloads\\personal\\study\\handson-learning\\loitering_data\\aboda_data\\video9.avi\")\n",
    "# video = cv2.VideoCapture(r\"C:\\Users\\MTC1COB\\Downloads\\personal\\study\\handson-learning\\loitering_data\\loitering_detection_output\\S1_T1_C_video3.mp4\")\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print(\"Error in opening or reading the file\")\n",
    "\n",
    "\n",
    "#collect first 10 frames to get the background model\n",
    "frame_arr = []\n",
    "for fid in range(10):\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "    ret, frame = video.read()\n",
    "    frame_arr.append(frame)\n",
    "    \n",
    "\n",
    "medianframe = np.median(frame_arr, axis=0).astype(dtype = np.uint8)\n",
    "# cv2.imshow(\"medianframe\",medianframe)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "graymedianframe = cv2.cvtColor(medianframe, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "previous_frame_centroid = (0,0)\n",
    "static_counter = 0\n",
    "image_arr = []\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if ret:\n",
    "        orig_image = frame\n",
    "        #convert current frame to gray scale\n",
    "        current_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #do Gaussian Filtering to smooth noise\n",
    "        current_frame = cv2.GaussianBlur(current_frame, (3,3), 1, 0)\n",
    "        \n",
    "        \n",
    "        #take abs diff to get mask of object and subtract the background \n",
    "        frame_diff = cv2.absdiff(current_frame, graymedianframe)\n",
    "        medianblur = cv2.medianBlur(frame_diff, 3)\n",
    "        ret, mask = cv2.threshold(medianblur, 100, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "        dilate = cv2.dilate(mask, kernel , iterations=4)\n",
    "\n",
    "        \n",
    "        #morphological closing operation\n",
    "        mask = cv2.morphologyEx(dilate, cv2.MORPH_CLOSE, (5,5), iterations=10)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 600:\n",
    "#                 cv2.rectangle(orig_image, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "                m = cv2.moments(cnt)\n",
    "                cx = int(m[\"m10\"]/m[\"m00\"])\n",
    "                cy = int(m[\"m01\"]/m[\"m00\"])\n",
    "                current_frame_centroid = (cx, cy)\n",
    "                \n",
    "                if current_frame_centroid == previous_frame_centroid:\n",
    "                    static_counter += 1\n",
    "#                 else:\n",
    "#                     static_counter = 0\n",
    "                \n",
    "                previous_frame_centroid = current_frame_centroid\n",
    "                \n",
    "                if static_counter >= 200:\n",
    "                    cv2.rectangle(orig_image, (x,y), (x+w, y+h), (0,0,255), 3)\n",
    "                else:\n",
    "                    cv2.rectangle(orig_image, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "                   \n",
    "        image_arr.append(orig_image)\n",
    "        cv2.imshow(\"Frame\",orig_image)\n",
    "        waitkey = cv2.waitKey(20)\n",
    "        if waitkey == 113 or waitkey == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43dae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_video = cv2.VideoWriter(\"aboda_dataset_output.mp4\",cv2.VideoWriter_fourcc(*'mp4v'), 24, (720,480))\n",
    "for index in range(len(image_arr)):\n",
    "    out_video.write(image_arr[index])\n",
    "out_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae1c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
